{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "      <h2>Entropy, Gini and Misclassification Rate</h2>\n",
    "      <h3>Q1.3. Contrast the effectiveness of Misclassification rate, Gini, Entropy as impurity measures in terms of precision, recall and accuracy.</h3>\n",
    "      <p>Here we train the data set to make a decision tree on numerical and categorical data and contrast the performance based on the impurity function we use.</p>\n",
    "      <p>The impurity functions examined here are:</p>\n",
    "      <ol>\n",
    "        <li>Entropy</li>\n",
    "        <li>Gini</li>\n",
    "        <li>Misclassification Rage</li>\n",
    "      </ol>\n",
    "   </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7</td>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4</td>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.10             0.90               7                   286   \n",
       "1                0.89             0.93               4                   249   \n",
       "2                0.38             0.50               2                   132   \n",
       "3                0.95             0.71               4                   151   \n",
       "4                0.84             0.84               5                   163   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years       sales  \\\n",
       "0                   4              0     1                      0       sales   \n",
       "1                   3              0     0                      0       sales   \n",
       "2                   3              0     1                      0  accounting   \n",
       "3                   4              0     0                      0       sales   \n",
       "4                   3              0     0                      0   technical   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1     low  \n",
       "2     low  \n",
       "3  medium  \n",
       "4     low  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "    <p>The original set is split into 80% train data 20% test data</p>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,\n",
    "    data.left,\n",
    "    test_size=0.2,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "    <p>While there are different ways to deal with numerical data when building a decision tree, here we split it into ranges based on their contribution to highest entropy.</p>\n",
    "    <p>After deciding the ranges, we convert each numerical data point into categorical data point based on the range to which they belong to.</p>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarunm/.local/lib/python2.7/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "map_range_sl = lambda x: '<=0.17' if x<=0.17 else ('0.18 to 0.29' if x <= 0.29 else ('0.30 to 0.39' if x<=0.39 else ('0.40 to 0.46' if x<=0.46 else ('0.47 to 0.53' if x<=0.53 else ('0.54 to 0.6' if x<=0.6 else ('0.61 to 0.67' if x<=0.67 else ('0.68 to 0.74' if x<=0.74 else ('0.75 to 0.8' if x<=0.8 else ('0.81 to 0.87' if x<=0.87 else ('0.88 to 0.94' if x<=0.94 else '>0.94'))))))))))\n",
    "X_train.satisfaction_level = X_train.satisfaction_level.apply(map_range_sl)\n",
    "X_test.satisfaction_level = X_test.satisfaction_level.apply(map_range_sl)\n",
    "\n",
    "map_range_le = lambda x: '<=0.44' if x<=0.44 else ('0.45 to 0.51' if x <= 0.51 else ('0.52 to 0.58' if x<=0.58 else ('0.59 to 0.65' if x<=0.65 else ('0.66 to 0.71' if x<=0.71 else ('0.72 to 0.78' if x<=0.78 else ('0.79 to 0.86' if x<=0.86 else ('0.87 to 0.93' if x<=0.93 else '>0.93'))))))) \n",
    "X_train.last_evaluation = X_train.last_evaluation.apply(map_range_le)\n",
    "X_test.last_evaluation = X_test.last_evaluation.apply(map_range_le)\n",
    "\n",
    "map_range_np = lambda x: '<=3' if x<=3 else '>3'\n",
    "X_train.number_project = X_train.number_project.apply(map_range_np)\n",
    "X_test.number_project = X_test.number_project.apply(map_range_np)\n",
    "\n",
    "map_range_amh = lambda x: '<=173' if x<=173 else ('174 to 229' if x<=229 else '>229')\n",
    "X_train.average_montly_hours = X_train.average_montly_hours.apply(map_range_amh)\n",
    "X_test.average_montly_hours = X_test.average_montly_hours.apply(map_range_amh)\n",
    "\n",
    "map_range_ts = lambda x : '<=3' if x <=3 else ('>3 and <=6' if x<=6 else '>6')\n",
    "X_train.time_spend_company = X_train.time_spend_company.apply(map_range_ts)\n",
    "X_test.time_spend_company = X_test.time_spend_company.apply(map_range_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "    <p>The following function creates a node with the details:</p>\n",
    "    <ul>\n",
    "      <li><b>value</b>: The actual value the node is supposed to represent. It can be a column name or a result value</li>\n",
    "      <li><b>is_leaf</b>: A boolean value indicating whether the current node is a leaf</li>\n",
    "      <li><b>children</b>: This is a python dictionary where the key represents branching condition and value represents the child node that the branch leads to</li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree_node(value, is_leaf):\n",
    "    new_node = dict()\n",
    "    new_node['value'] = value\n",
    "    new_node['is_leaf'] = is_leaf\n",
    "    new_node['children'] = dict()\n",
    "    return new_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "    <p>The following function computes the impurity. For this question, we explre three impurity functions</p>\n",
    "    <ul>\n",
    "      <li>Entropy\n",
    "        <br>\n",
    "        $$E = -(qlogq + (1-q)log(1-q))$$\n",
    "        <br>\n",
    "      </li>\n",
    "      <li>Gini\n",
    "        <br>\n",
    "        $$E = 2q(1-q)$$\n",
    "        <br>\n",
    "      </li>\n",
    "      <li>Misclassification Rate\n",
    "        <br>\n",
    "        $$E = min(q,1-q)$$\n",
    "        <br>\n",
    "      </li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_impurity(pos_ratio,neg_ratio,impurity_function):\n",
    "    if impurity_function == 'entropy':\n",
    "        if pos_ratio == 0 or pos_ratio == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return -((pos_ratio*np.log(pos_ratio)) + (neg_ratio*np.log(neg_ratio)))\n",
    "    elif impurity_function == 'gini_index':\n",
    "        return (2*pos_ratio*neg_ratio)\n",
    "    elif impurity_function == 'misclassification_rate':\n",
    "        return min(pos_ratio,neg_ratio)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "    <p>We now introduce a python class to create training and predict functions as member functions. We also store the decision tree in a member variable of the same class.</p>\n",
    "    <p>The following are the member functions of the class:</p>\n",
    "    <ul>\n",
    "      <li><b>train</b>: Will take the training data and create the decision tree</li>\n",
    "      <li><b>predict</b>: Will take the input data and predict the class to which each row belongs to</li>\n",
    "      <li><b>get_model</b>: Will return the decision tree object</li>\n",
    "      <li><b>compute_accuracy</b>: Will check predicted value with the actual value and compute the accuracy</li>\n",
    "      <li><b>get_precision_recall_f1score</b>: Will compute precision, recall and F1 Score. Formula given later</li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    decision_tree = None\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.decision_tree\n",
    "    \n",
    "    def get_row_result(self,row,tree_node):\n",
    "        if tree_node['is_leaf']:\n",
    "            return tree_node['value']\n",
    "        \n",
    "        key = tree_node['value']\n",
    "        val = row[key]\n",
    "        if val not in tree_node['children']:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.get_row_result(row,tree_node['children'][val])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        y_pred = list()\n",
    "        for index,row in X.iterrows():\n",
    "            result = self.get_row_result(row,self.decision_tree)\n",
    "            y_pred.append(result)\n",
    "        df = pd.DataFrame({'Y_predicted': y_pred})\n",
    "        return df\n",
    "    \n",
    "    def compute_accuracy(self,Y_actual,Y_predict):\n",
    "        ya = Y_actual.values.tolist()\n",
    "        yp = Y_predict.values.tolist()\n",
    "        l = len(ya)\n",
    "        count = 0\n",
    "        for i in range(0,l):\n",
    "            if int(ya[i])==int(yp[i]):\n",
    "                count+=1\n",
    "        return float(count)/float(l)\n",
    "    \n",
    "    def get_precision_recall_f1score(self,Y_actual,Y_predict):\n",
    "        ya = Y_actual.values.tolist()\n",
    "        yp = Y_predict.values.tolist()\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        l = len(ya)\n",
    "        for i in range(0,l):\n",
    "            if int(ya[i])==0 and int(yp[i])==0:\n",
    "                #true negative\n",
    "                tn += 1\n",
    "            elif int(ya[i])==0 and int(yp[i])==1:\n",
    "                #false positive\n",
    "                fp += 1\n",
    "            elif int(ya[i])==1 and int(yp[i])==0:\n",
    "                #false negative\n",
    "                fn += 1\n",
    "            else:\n",
    "                #true positive\n",
    "                tp += 1\n",
    "        precision = float(tp)/(float(tp)+float(fp))\n",
    "        recall = float(tp)/(float(tp)+float(fn))\n",
    "        f1_score = 2.0/((1.0/recall)+(1.0/precision))\n",
    "        return (precision,recall,f1_score)\n",
    "    \n",
    "    \n",
    "    def train(self, curr_data,curr_parent_object,curr_condition, exclude_cols, impurity_function):\n",
    "        curr_parent_str = curr_parent_object['value']\n",
    "        if curr_parent_str not in exclude_cols:\n",
    "            exclude_cols.append(curr_parent_str)\n",
    "        m = len(curr_data)\n",
    "        G = dict()\n",
    "        for col in curr_data:\n",
    "            if col in exclude_cols:\n",
    "                continue\n",
    "            I = 0.0\n",
    "            col_pos = 0\n",
    "            col_neg = 0\n",
    "            int_info = 0\n",
    "            for categ in curr_data[col].unique():\n",
    "                pos = 0\n",
    "                neg = 0\n",
    "                if 1 in curr_data.groupby([col])['left'].value_counts()[categ]: \n",
    "                    pos = curr_data.groupby([col])['left'].value_counts()[categ][1]\n",
    "                if 0 in curr_data.groupby([col])['left'].value_counts()[categ]:\n",
    "                    neg = curr_data.groupby([col])['left'].value_counts()[categ][0]\n",
    "                col_pos += pos\n",
    "                col_neg += neg\n",
    "                pos_ratio = float(pos)/float(pos+neg)\n",
    "                neg_ratio = float(neg)/float(pos+neg)\n",
    "                impurity = compute_impurity(pos_ratio,neg_ratio, impurity_function)\n",
    "                Si_S = float(pos+neg)/float(m) \n",
    "                I += Si_S*impurity\n",
    "                int_info += Si_S*np.log(Si_S)\n",
    "            col_pos_ratio = float(col_pos)/float(col_pos+col_neg)\n",
    "            col_neg_ratio = float(col_neg)/float(col_pos+col_neg)\n",
    "            E = compute_impurity(col_pos_ratio,col_neg_ratio, impurity_function)\n",
    "            G[col] = ((E-I)/(-1*int_info))\n",
    "    \n",
    "        if not G:\n",
    "            if curr_parent_str == 'dummy_parent':\n",
    "                return self.decision_tree\n",
    "            for categ in curr_data[col].unique():\n",
    "                if 0 in curr_data.groupby([curr_parent_str])['left'].value_counts()[curr_condition] and 1 in curr_data.groupby([curr_parent_str])['left'].value_counts()[curr_condition]:\n",
    "                    if curr_data.groupby([curr_parent_str])['left'].value_counts()[curr_condition][0] > curr_data.groupby([curr_parent_str])['left'].value_counts()[curr_condition][1]:\n",
    "                        new_node = create_tree_node('0',True)\n",
    "                        curr_parent_object['children'][curr_condition] = new_node\n",
    "                    else:\n",
    "                        new_node = create_tree_node('1',True)\n",
    "                        curr_parent_object['children'][curr_condition] = new_node\n",
    "                elif 0 in curr_data.groupby([curr_parent_str])['left'].value_counts()[curr_condition]:\n",
    "                    new_node = create_tree_node('0',True)\n",
    "                    curr_parent_object['children'][curr_condition] = new_node\n",
    "                elif 1 in curr_data.groupby([curr_parent_str])['left'].value_counts()[curr_condition]:\n",
    "                    new_node = create_tree_node('1',True)\n",
    "                    curr_parent_object['children'][curr_condition] = new_node\n",
    "                else:\n",
    "                    new_node = create_tree_node('0',True)\n",
    "                    curr_parent_object['children'][curr_condition] = new_node\n",
    "            return self.decision_tree\n",
    "    \n",
    "        max_col = max(G, key=G.get)\n",
    "        \n",
    "        new_node = create_tree_node(max_col,False)\n",
    "        if self.decision_tree is None:\n",
    "            self.decision_tree = new_node\n",
    "        else:\n",
    "            curr_parent_object['children'][curr_condition] = new_node\n",
    "\n",
    "        temp_exclude_cols = exclude_cols[:]\n",
    "        for cond in curr_data[max_col].unique():\n",
    "            self.train(curr_data.loc[curr_data[max_col]==cond].copy() , new_node, cond,temp_exclude_cols, impurity_function)\n",
    "    \n",
    "        return self.decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "    <p>The decision tree is built using the following algorithm: </p>\n",
    "    <ol>\n",
    "      <li>Input data</li>\n",
    "      <li>Compute impurities (entropy) of all columns</li>\n",
    "      <li>Compute Average entropy of all columns with the following formula</li>\n",
    "      $$I(S,A) = \\sum_{i}^{ }\\frac{|{S_{i}}^{ }|}{|S|}\\cdot E({S_{i}}^{ })$$\n",
    "      <li>Compute Gain of columns using the following formula</li>\n",
    "      $$G(S,A) = E(S) - I(S,A)$$\n",
    "      <li>If no more Gain is left to compute, declare leaf node and fill corresponding result value</li>\n",
    "      <li>Find the column with maximum gain and make it a node</li>\n",
    "      <li>For each category of column with maximum Gain, repeat from step 2</li>\n",
    "    </ol>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarunm/.local/lib/python2.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy model Accuracy : 98.8876529477\n",
      "Gini index model Accuracy : 98.8876529477\n",
      "Misclassification Rate index model Accuracy : 98.8876529477\n"
     ]
    }
   ],
   "source": [
    "dummy_node = dict()\n",
    "dummy_node['value'] = 'dummy_parent'\n",
    "\n",
    "entropy_dt = DecisionTree()\n",
    "gini_dt = DecisionTree()\n",
    "mr_dt = DecisionTree()\n",
    "\n",
    "entropy_model = entropy_dt.train(X_train.copy(),dummy_node,'dummy_condition',['left'],'entropy')\n",
    "gini_model = gini_dt.train(X_train.copy(),dummy_node,'dummy_condition',['left'],'gini_index')\n",
    "mr_model = mr_dt.train(X_train.copy(),dummy_node,'dummy_condition',['left'],'misclassification_rate')\n",
    "\n",
    "entropy_left_predict = entropy_dt.predict(X_train)\n",
    "gini_left_predict = gini_dt.predict(X_train)\n",
    "mr_left_predict = mr_dt.predict(X_train)\n",
    "\n",
    "entropy_acc = entropy_dt.compute_accuracy(X_train['left'],entropy_left_predict['Y_predicted'])\n",
    "gini_acc = gini_dt.compute_accuracy(X_train['left'],gini_left_predict['Y_predicted'])\n",
    "mr_acc = mr_dt.compute_accuracy(X_train['left'],mr_left_predict['Y_predicted'])\n",
    "\n",
    "print 'Train Entropy model Accuracy : '+str(entropy_acc*100)\n",
    "print 'Train Gini index model Accuracy : '+str(gini_acc*100)\n",
    "print 'Train Misclassification Rate index model Accuracy : '+str(mr_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Entropy model Accuracy : 96.4857651246\n",
      "Test Gini index model Accuracy : 96.4857651246\n",
      "Test Misclassification Rate index model Accuracy : 96.4857651246\n"
     ]
    }
   ],
   "source": [
    "entropy_left_predict = entropy_dt.predict(X_test)\n",
    "gini_left_predict = gini_dt.predict(X_test)\n",
    "mr_left_predict = mr_dt.predict(X_test)\n",
    "\n",
    "entropy_acc = entropy_dt.compute_accuracy(X_test['left'],entropy_left_predict['Y_predicted'])\n",
    "gini_acc = gini_dt.compute_accuracy(X_test['left'],gini_left_predict['Y_predicted'])\n",
    "mr_acc = mr_dt.compute_accuracy(X_test['left'],mr_left_predict['Y_predicted'])\n",
    "\n",
    "print 'Test Entropy model Accuracy : '+str(entropy_acc*100)\n",
    "print 'Test Gini index model Accuracy : '+str(gini_acc*100)\n",
    "print 'Test Misclassification Rate index model Accuracy : '+str(mr_acc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <body>\n",
    "    <p>Precision, recall and F1 score are computed using the following formula: </p>\n",
    "    <br>\n",
    "    $$Precision = \\frac{True Positive}{True Positive + False Positive}$$\n",
    "    <br>\n",
    "    $$Recall = \\frac{True Positive}{True Positive + False Negative}$$\n",
    "    <br>\n",
    "    $$F1 Score = \\frac{2}{\\frac{1}{Recall} + \\frac{1}{Precision}}$$\n",
    "    <br>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy Precision : 0.937621832359\n",
      "Entropy Recall : 0.910984848485\n",
      "Entropy F1 Score : 0.924111431316\n",
      "\n",
      "\n",
      "Gini Index Precision : 0.937621832359\n",
      "Gini Index Recall : 0.910984848485\n",
      "Gini Index F1 Score : 0.924111431316\n",
      "\n",
      "\n",
      "Gini Index Precision : 0.937621832359\n",
      "Gini Index Recall : 0.910984848485\n",
      "Gini Index F1 Score : 0.924111431316\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entropy_precision,entropy_recall,entropy_f1_score = entropy_dt.get_precision_recall_f1score(X_test['left'],entropy_left_predict['Y_predicted'])\n",
    "print 'Entropy Precision : '+str(entropy_precision)\n",
    "print 'Entropy Recall : '+str(entropy_recall)\n",
    "print 'Entropy F1 Score : '+str(entropy_f1_score)\n",
    "print\n",
    "print\n",
    "gini_precision,gini_recall,gini_f1_score = gini_dt.get_precision_recall_f1score(X_test['left'],gini_left_predict['Y_predicted'])\n",
    "print 'Gini Index Precision : '+str(gini_precision)\n",
    "print 'Gini Index Recall : '+str(gini_recall)\n",
    "print 'Gini Index F1 Score : '+str(gini_f1_score)\n",
    "print\n",
    "print\n",
    "mr_precision,mr_recall,mr_f1_score = mr_dt.get_precision_recall_f1score(X_test['left'],mr_left_predict['Y_predicted'])\n",
    "print 'Gini Index Precision : '+str(mr_precision)\n",
    "print 'Gini Index Recall : '+str(mr_recall)\n",
    "print 'Gini Index F1 Score : '+str(mr_f1_score)\n",
    "print\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
